{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder for pan-cancer gene expression\n",
    "\n",
    "**Gregory Way 2017**\n",
    "\n",
    "This script trains and outputs results for a [variational autoencoder (VAE)](https://arxiv.org/abs/1312.6114)\n",
    "applied to gene expressiond data across 33 different cancer-types from The Cancer Genome Atlas (TCGA).\n",
    "\n",
    "A VAE aproximates the data generating function for the cancer data and learns the lower dimensional manifold a tumor occupies in gene expression space. By compressing the gene expression space into lower dimensional space, the VAE would, ideally, learn biological principles, such as cancer hallmark pathway activations, that help explain how tumors are similar and different. The VAE is also a generative model with a latent space that can be interpolated to observe transitions between cancer states.\n",
    "\n",
    "The particular model trained in this notebook consists of gene expression input (5000 most variably expressed genes by median absolute deviation) compressed down into two length 100 vectors (mean and variance encoded spaces) which are made deterministic through the reparameterization trick of sampling an epsilon vector from the uniform distribution. The encoded layer is then decoded back to original 5000 dimensions through a single reconstruction layer. I included a layer of batch normalization in the encoding step to prevent dead nodes. The encoding scheme also uses relu activation while the decoder uses a sigmoid activation to enforce positive activations. All weights are glorot uniform initialized. \n",
    "\n",
    "Another trick used here to encourage manifold learning is _warm start_ as discussed in [Sonderby et al. 2016](https://arxiv.org/abs/1602.02282). With warm starts, we add a parameter _beta_, which controls the contribution of the KL divergence loss in the total VAE loss (reconstruction + (beta * KL)). In this setting, the model begins training deterministically as a vanilla autoencoder (_beta_ = 0) and slowly ramps up after each epoch linearly until _beta_ = 1. We set hyperparameter _kappa_ = 0.05 to control at what linear rate _beta_ increases.\n",
    "\n",
    "Much of this script is inspired by the [keras variational_autoencoder.py example](https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Functions and Classes\n",
    "\n",
    "This will facilitate connections between layers and also custom hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "                                K.exp(z_log_var_encoded), axis=-1)\n",
    "        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Warm-up as described in Sonderby et al. LVAE\n",
    "\n",
    "This is modified code from https://github.com/fchollet/keras/issues/2595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta):\n",
    "        self.beta = beta\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Gene Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10459, 5000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPS4Y1</th>\n",
       "      <th>XIST</th>\n",
       "      <th>KRT5</th>\n",
       "      <th>AGR2</th>\n",
       "      <th>CEACAM5</th>\n",
       "      <th>KRT6A</th>\n",
       "      <th>KRT14</th>\n",
       "      <th>CEACAM6</th>\n",
       "      <th>DDX3Y</th>\n",
       "      <th>KDM5D</th>\n",
       "      <th>...</th>\n",
       "      <th>FAM129A</th>\n",
       "      <th>C8orf48</th>\n",
       "      <th>CDK5R1</th>\n",
       "      <th>FAM81A</th>\n",
       "      <th>C13orf18</th>\n",
       "      <th>GDPD3</th>\n",
       "      <th>SMAGP</th>\n",
       "      <th>C2orf85</th>\n",
       "      <th>POU5F1B</th>\n",
       "      <th>CHST2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0047-01</th>\n",
       "      <td>0.678296</td>\n",
       "      <td>0.289910</td>\n",
       "      <td>0.034230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.746797</td>\n",
       "      <td>0.687833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440610</td>\n",
       "      <td>0.428782</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.634340</td>\n",
       "      <td>0.580662</td>\n",
       "      <td>0.294313</td>\n",
       "      <td>0.458134</td>\n",
       "      <td>0.478219</td>\n",
       "      <td>0.168263</td>\n",
       "      <td>0.638497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0055-01</th>\n",
       "      <td>0.200633</td>\n",
       "      <td>0.654917</td>\n",
       "      <td>0.181993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100606</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.092586</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.140642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620658</td>\n",
       "      <td>0.363207</td>\n",
       "      <td>0.592269</td>\n",
       "      <td>0.602755</td>\n",
       "      <td>0.610192</td>\n",
       "      <td>0.374569</td>\n",
       "      <td>0.722420</td>\n",
       "      <td>0.271356</td>\n",
       "      <td>0.160465</td>\n",
       "      <td>0.602560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RPS4Y1      XIST      KRT5  AGR2  CEACAM5     KRT6A  \\\n",
       "TCGA-02-0047-01  0.678296  0.289910  0.034230   0.0      0.0  0.084731   \n",
       "TCGA-02-0055-01  0.200633  0.654917  0.181993   0.0      0.0  0.100606   \n",
       "\n",
       "                    KRT14   CEACAM6     DDX3Y     KDM5D    ...      FAM129A  \\\n",
       "TCGA-02-0047-01  0.031863  0.037709  0.746797  0.687833    ...     0.440610   \n",
       "TCGA-02-0055-01  0.050011  0.092586  0.103725  0.140642    ...     0.620658   \n",
       "\n",
       "                  C8orf48    CDK5R1    FAM81A  C13orf18     GDPD3     SMAGP  \\\n",
       "TCGA-02-0047-01  0.428782  0.732819  0.634340  0.580662  0.294313  0.458134   \n",
       "TCGA-02-0055-01  0.363207  0.592269  0.602755  0.610192  0.374569  0.722420   \n",
       "\n",
       "                  C2orf85   POU5F1B     CHST2  \n",
       "TCGA-02-0047-01  0.478219  0.168263  0.638497  \n",
       "TCGA-02-0055-01  0.271356  0.160465  0.602560  \n",
       "\n",
       "[2 rows x 5000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnaseq_file = os.path.join('data', 'pancan_scaled_zeroone_rnaseq.tsv')\n",
    "rnaseq_df = pd.read_table(rnaseq_file, index_col=0)\n",
    "print(rnaseq_df.shape)\n",
    "rnaseq_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split 10% test set randomly\n",
    "test_set_percent = 0.1\n",
    "rnaseq_test_df = rnaseq_df.sample(frac=test_set_percent)\n",
    "rnaseq_train_df = rnaseq_df.drop(rnaseq_test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set hyper parameters\n",
    "batch_size = 128\n",
    "original_dim = 5000\n",
    "latent_dim = 100\n",
    "\n",
    "epochs = 50\n",
    "epsilon_std = 1.0\n",
    "\n",
    "beta = K.variable(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Input place holder for RNAseq data with specific input size\n",
    "rnaseq_input = Input(shape=(original_dim, ))\n",
    "\n",
    "# Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "# Each layer is initialized with glorot uniform weights and each step (dense connections, batch norm,\n",
    "# and relu activation) are funneled separately\n",
    "# Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "z_mean_dense_linear = Dense(latent_dim, kernel_initializer='glorot_uniform')(rnaseq_input)\n",
    "z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "z_log_var_dense_linear = Dense(latent_dim, kernel_initializer='glorot_uniform')(rnaseq_input)\n",
    "z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "# return the encoded and randomly sampled z vector\n",
    "# Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "z = Lambda(sampling, output_shape=(latent_dim, ))([z_mean_encoded, z_log_var_encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The decoding layer is much simpler with a single layer glorot uniform initialized and sigmoid activation\n",
    "decoder_to_reconstruct = Dense(original_dim, kernel_initializer='glorot_uniform', activation='sigmoid')\n",
    "rnaseq_reconstruct = decoder_to_reconstruct(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the encoder and decoder to make the VAE\n",
    "\n",
    "The `CustomVariationalLayer()` includes the VAE loss function (reconstruction + (beta * KL)), which is what will drive our model to learn an interpretable representation of gene expression space.\n",
    "\n",
    "The VAE is compiled with an Adam optimizer and built-in custom loss function. The `loss_weights` parameter ensures beta is updated at each epoch end callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 5000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           500100      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           500100      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 100)           400         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 100)           400         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 100)           0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 100)           0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 100)           0           activation_1[0][0]               \n",
      "                                                                   activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 5000)          505000      lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_1 (Cust [(None, 5000), (None, 0           input_1[0][0]                    \n",
      "                                                                   dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,506,000\n",
      "Trainable params: 1,505,600\n",
      "Non-trainable params: 400\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gway/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Output \"custom_variational_layer_1\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_1\" during training.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "vae_layer = CustomVariationalLayer()([rnaseq_input, rnaseq_reconstruct])\n",
    "vae = Model(rnaseq_input, vae_layer)\n",
    "vae.compile(optimizer='Adam', loss=None, loss_weights=[beta])\n",
    "\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 670.50 483.00\" width=\"671pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 666.5,-479 666.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139988461881776 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139988461881776</title>\n",
       "<polygon fill=\"none\" points=\"345.5,-438.5 345.5,-474.5 470.5,-474.5 470.5,-438.5 345.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-452.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139988461881328 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139988461881328</title>\n",
       "<polygon fill=\"none\" points=\"158,-365.5 158,-401.5 260,-401.5 260,-365.5 158,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-379.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 139988461881776&#45;&gt;139988461881328 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139988461881776-&gt;139988461881328</title>\n",
       "<path d=\"M360.335,-438.494C332.113,-428.425 296.172,-415.602 266.399,-404.979\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"267.561,-401.678 256.966,-401.614 265.209,-408.27 267.561,-401.678\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988461879536 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139988461879536</title>\n",
       "<polygon fill=\"none\" points=\"357,-365.5 357,-401.5 459,-401.5 459,-365.5 357,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-379.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 139988461881776&#45;&gt;139988461879536 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139988461881776-&gt;139988461879536</title>\n",
       "<path d=\"M408,-438.313C408,-430.289 408,-420.547 408,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"411.5,-411.529 408,-401.529 404.5,-411.529 411.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988473237800 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139988473237800</title>\n",
       "<polygon fill=\"none\" points=\"351.5,-0.5 351.5,-36.5 662.5,-36.5 662.5,-0.5 351.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"507\" y=\"-14.8\">custom_variational_layer_1: CustomVariationalLayer</text>\n",
       "</g>\n",
       "<!-- 139988461881776&#45;&gt;139988473237800 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139988461881776-&gt;139988473237800</title>\n",
       "<path d=\"M450.757,-438.449C497.549,-416.635 566,-374.037 566,-311.5 566,-311.5 566,-311.5 566,-163.5 566,-119.566 542.193,-73.3423 524.824,-45.4659\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"527.573,-43.2688 519.225,-36.7453 521.683,-47.0511 527.573,-43.2688\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988461880880 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139988461880880</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 260,-328.5 260,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-306.8\">batch_normalization_1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139988461881328&#45;&gt;139988461880880 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139988461881328-&gt;139988461880880</title>\n",
       "<path d=\"M189.876,-365.313C179.881,-356.33 167.49,-345.193 156.577,-335.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.725,-332.61 148.948,-328.529 154.046,-337.816 158.725,-332.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988461880432 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139988461880432</title>\n",
       "<polygon fill=\"none\" points=\"278,-292.5 278,-328.5 538,-328.5 538,-292.5 278,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-306.8\">batch_normalization_2: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139988461879536&#45;&gt;139988461880432 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139988461879536-&gt;139988461880432</title>\n",
       "<path d=\"M408,-365.313C408,-357.289 408,-347.547 408,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"411.5,-338.529 408,-328.529 404.5,-338.529 411.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988461880656 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139988461880656</title>\n",
       "<polygon fill=\"none\" points=\"112,-219.5 112,-255.5 260,-255.5 260,-219.5 112,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-233.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 139988461880880&#45;&gt;139988461880656 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139988461880880-&gt;139988461880656</title>\n",
       "<path d=\"M143.556,-292.313C150.366,-283.679 158.745,-273.055 166.255,-263.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169.124,-265.548 172.569,-255.529 163.628,-261.213 169.124,-265.548\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988592217504 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139988592217504</title>\n",
       "<polygon fill=\"none\" points=\"334,-219.5 334,-255.5 482,-255.5 482,-219.5 334,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-233.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 139988461880432&#45;&gt;139988592217504 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139988461880432-&gt;139988592217504</title>\n",
       "<path d=\"M408,-292.313C408,-284.289 408,-274.547 408,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"411.5,-265.529 408,-255.529 404.5,-265.529 411.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988592216104 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139988592216104</title>\n",
       "<polygon fill=\"none\" points=\"346.5,-146.5 346.5,-182.5 469.5,-182.5 469.5,-146.5 346.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-160.8\">lambda_1: Lambda</text>\n",
       "</g>\n",
       "<!-- 139988461880656&#45;&gt;139988592216104 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139988461880656-&gt;139988592216104</title>\n",
       "<path d=\"M239.175,-219.494C270.931,-209.338 311.447,-196.379 344.828,-185.704\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"346.031,-188.994 354.49,-182.614 343.899,-182.326 346.031,-188.994\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988592217504&#45;&gt;139988592216104 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139988592217504-&gt;139988592216104</title>\n",
       "<path d=\"M408,-219.313C408,-211.289 408,-201.547 408,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"411.5,-192.529 408,-182.529 404.5,-192.529 411.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988957259536 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139988957259536</title>\n",
       "<polygon fill=\"none\" points=\"397,-73.5 397,-109.5 499,-109.5 499,-73.5 397,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448\" y=\"-87.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 139988592216104&#45;&gt;139988957259536 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139988592216104-&gt;139988957259536</title>\n",
       "<path d=\"M417.683,-146.313C422.4,-137.941 428.171,-127.697 433.407,-118.403\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"436.547,-119.959 438.406,-109.529 430.448,-116.523 436.547,-119.959\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139988957259536&#45;&gt;139988473237800 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139988957259536-&gt;139988473237800</title>\n",
       "<path d=\"M462.282,-73.3129C469.529,-64.5918 478.464,-53.8402 486.436,-44.2459\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"489.15,-46.4569 492.849,-36.5288 483.766,-41.983 489.15,-46.4569\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the connections of the custom VAE model\n",
    "output_model_file = os.path.join('figures', 'onehidden_warmup_batchnorm_vae.png')\n",
    "plot_model(vae, to_file=output_model_file)\n",
    "\n",
    "SVG(model_to_dot(vae).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "The training data is shuffled after every epoch and 10% of the data is heldout for calculating validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9413 samples, validate on 1046 samples\n",
      "Epoch 1/50\n",
      "9413/9413 [==============================] - 4s - loss: 3020.5910 - val_loss: 3143.1783\n",
      "Epoch 2/50\n",
      "9413/9413 [==============================] - 4s - loss: 2829.4949 - val_loss: 2833.7952\n",
      "Epoch 3/50\n",
      "9413/9413 [==============================] - 4s - loss: 2791.2786 - val_loss: 2799.1504\n",
      "Epoch 4/50\n",
      "9413/9413 [==============================] - 4s - loss: 2772.1242 - val_loss: 2786.9416\n",
      "Epoch 5/50\n",
      "9413/9413 [==============================] - 4s - loss: 2759.6945 - val_loss: 2771.3542\n",
      "Epoch 6/50\n",
      "9413/9413 [==============================] - 4s - loss: 2750.9641 - val_loss: 2750.4299\n",
      "Epoch 7/50\n",
      "9413/9413 [==============================] - 4s - loss: 2743.9815 - val_loss: 2745.1754\n",
      "Epoch 8/50\n",
      "9413/9413 [==============================] - 4s - loss: 2738.7934 - val_loss: 2742.5162\n",
      "Epoch 9/50\n",
      "9413/9413 [==============================] - 4s - loss: 2734.0398 - val_loss: 2737.2689\n",
      "Epoch 10/50\n",
      "9413/9413 [==============================] - 4s - loss: 2730.3547 - val_loss: 2739.2972\n",
      "Epoch 11/50\n",
      "9413/9413 [==============================] - 4s - loss: 2726.6954 - val_loss: 2725.5695\n",
      "Epoch 12/50\n",
      "9413/9413 [==============================] - 4s - loss: 2723.2110 - val_loss: 2731.2412\n",
      "Epoch 13/50\n",
      "9413/9413 [==============================] - 4s - loss: 2720.3083 - val_loss: 2725.3685\n",
      "Epoch 14/50\n",
      "9413/9413 [==============================] - 4s - loss: 2717.5674 - val_loss: 2719.9242\n",
      "Epoch 15/50\n",
      "9413/9413 [==============================] - 4s - loss: 2714.7616 - val_loss: 2716.2276\n",
      "Epoch 16/50\n",
      "9413/9413 [==============================] - 5s - loss: 2712.4666 - val_loss: 2715.6034\n",
      "Epoch 17/50\n",
      "9413/9413 [==============================] - 4s - loss: 2709.8875 - val_loss: 2713.3428\n",
      "Epoch 18/50\n",
      "9413/9413 [==============================] - 4s - loss: 2708.0771 - val_loss: 2712.6389\n",
      "Epoch 19/50\n",
      "9413/9413 [==============================] - 4s - loss: 2706.2668 - val_loss: 2708.1950\n",
      "Epoch 20/50\n",
      "9413/9413 [==============================] - 4s - loss: 2704.1458 - val_loss: 2705.4758\n",
      "Epoch 21/50\n",
      "9413/9413 [==============================] - 4s - loss: 2703.0933 - val_loss: 2704.2712\n",
      "Epoch 22/50\n",
      "9413/9413 [==============================] - 4s - loss: 2701.2411 - val_loss: 2703.5720\n",
      "Epoch 23/50\n",
      "9413/9413 [==============================] - 4s - loss: 2700.1093 - val_loss: 2702.5334\n",
      "Epoch 24/50\n",
      "9413/9413 [==============================] - 4s - loss: 2698.2189 - val_loss: 2701.0247\n",
      "Epoch 25/50\n",
      "9413/9413 [==============================] - 4s - loss: 2696.7310 - val_loss: 2698.5178\n",
      "Epoch 26/50\n",
      "9413/9413 [==============================] - 4s - loss: 2695.6006 - val_loss: 2699.0227\n",
      "Epoch 27/50\n",
      "9413/9413 [==============================] - 4s - loss: 2694.3588 - val_loss: 2697.7285\n",
      "Epoch 28/50\n",
      "9413/9413 [==============================] - 4s - loss: 2693.0050 - val_loss: 2696.4214\n",
      "Epoch 29/50\n",
      "9413/9413 [==============================] - 4s - loss: 2692.0741 - val_loss: 2696.4177\n",
      "Epoch 30/50\n",
      "9413/9413 [==============================] - 4s - loss: 2691.3407 - val_loss: 2695.9129\n",
      "Epoch 31/50\n",
      "9413/9413 [==============================] - 4s - loss: 2689.8131 - val_loss: 2693.8564\n",
      "Epoch 32/50\n",
      "9413/9413 [==============================] - 4s - loss: 2688.4962 - val_loss: 2690.7917\n",
      "Epoch 33/50\n",
      "9413/9413 [==============================] - 4s - loss: 2687.9791 - val_loss: 2689.9276\n",
      "Epoch 34/50\n",
      "9413/9413 [==============================] - 4s - loss: 2687.1568 - val_loss: 2690.0316\n",
      "Epoch 35/50\n",
      "9413/9413 [==============================] - 4s - loss: 2686.2160 - val_loss: 2688.8143\n",
      "Epoch 36/50\n",
      "9413/9413 [==============================] - 4s - loss: 2685.3195 - val_loss: 2687.7488\n",
      "Epoch 37/50\n",
      "9413/9413 [==============================] - 5s - loss: 2684.7534 - val_loss: 2688.5655\n",
      "Epoch 38/50\n",
      "9413/9413 [==============================] - 5s - loss: 2684.2060 - val_loss: 2684.8429\n",
      "Epoch 39/50\n",
      "9413/9413 [==============================] - 4s - loss: 2683.5948 - val_loss: 2687.4718\n",
      "Epoch 40/50\n",
      "9413/9413 [==============================] - 4s - loss: 2682.6767 - val_loss: 2687.3795\n",
      "Epoch 41/50\n",
      "9413/9413 [==============================] - 5s - loss: 2682.0019 - val_loss: 2684.6925\n",
      "Epoch 42/50\n",
      "9413/9413 [==============================] - 4s - loss: 2681.0464 - val_loss: 2684.2804\n",
      "Epoch 43/50\n",
      "9413/9413 [==============================] - 4s - loss: 2680.4201 - val_loss: 2685.3815\n",
      "Epoch 44/50\n",
      "9413/9413 [==============================] - 4s - loss: 2679.9616 - val_loss: 2682.2357\n",
      "Epoch 45/50\n",
      "9413/9413 [==============================] - 4s - loss: 2679.6420 - val_loss: 2682.5770\n",
      "Epoch 46/50\n",
      "9413/9413 [==============================] - 4s - loss: 2678.7185 - val_loss: 2680.2959\n",
      "Epoch 47/50\n",
      "9413/9413 [==============================] - 4s - loss: 2677.9637 - val_loss: 2681.4794\n",
      "Epoch 48/50\n",
      "9413/9413 [==============================] - 5s - loss: 2677.8393 - val_loss: 2678.6853\n",
      "Epoch 49/50\n",
      "9413/9413 [==============================] - 5s - loss: 2676.9589 - val_loss: 2678.3011\n",
      "Epoch 50/50\n",
      "9413/9413 [==============================] - 4s - loss: 2676.2463 - val_loss: 2681.3535\n",
      "CPU times: user 10min 8s, sys: 1min 27s, total: 11min 35s\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = vae.fit(np.array(rnaseq_train_df),\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(np.array(rnaseq_test_df), np.array(rnaseq_test_df)),\n",
    "               callbacks=[WarmUpCallback(beta)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAFfCAYAAAA8vaR4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7KziJQ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51a0222fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training performance\n",
    "history_df = pd.DataFrame(hist.history)\n",
    "hist_plot_file = os.path.join('figures', 'onehidden_warmup_batchnorm.svg')\n",
    "ax = history_df.plot()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('VAE Loss')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(hist_plot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and output trained models\n",
    "\n",
    "We are interested in:\n",
    "\n",
    "1. The model to encode/compress the input gene expression data\n",
    "  * Can be possibly used to compress other tumors\n",
    "2. The model to decode/decompress the latent space back into gene expression space\n",
    "  * This is our generative model\n",
    "3. The latent space compression of all pan cancer TCGA samples\n",
    "  * Non-linear reduced dimension representation of tumors can be used as features for various tasks\n",
    "    * Supervised learning tasks predicting specific gene inactivation events\n",
    "    * Interpolating across this space to observe how gene expression changes between two cancer states\n",
    "4. The weights used to compress each latent node\n",
    "  * Potentially indicate learned biology differentially activating tumors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model to compress input\n",
    "encoder = Model(rnaseq_input, z_mean_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Encode rnaseq into the hidden/latent representation - and save output\n",
    "encoded_rnaseq_df = encoder.predict_on_batch(rnaseq_df)\n",
    "encoded_rnaseq_df = pd.DataFrame(encoded_rnaseq_df, index=rnaseq_df.index)\n",
    "\n",
    "encoded_rnaseq_df.columns.name = 'sample_id'\n",
    "encoded_rnaseq_df.columns = encoded_rnaseq_df.columns + 1\n",
    "encoded_file = os.path.join('models', 'onehidden_warmup_batchnorm.tsv')\n",
    "encoded_rnaseq_df.to_csv(encoded_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_id\n",
      "92    22457.835938\n",
      "71    21948.853516\n",
      "95    21566.316406\n",
      "96    20561.634766\n",
      "76    20312.646484\n",
      "82    19855.769531\n",
      "31    19647.775391\n",
      "27    19642.291016\n",
      "7     19581.240234\n",
      "10    19555.455078\n",
      "dtype: float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sample_id\n",
       "63    11147.363281\n",
       "78    11026.460938\n",
       "32    10941.249023\n",
       "36    10926.122070\n",
       "42    10875.253906\n",
       "14    10805.651367\n",
       "8     10704.379883\n",
       "15     9136.851562\n",
       "68     7844.464355\n",
       "58     7409.948730\n",
       "dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most and least activated nodes\n",
    "top_active_nodes = encoded_rnaseq_df.sum(axis=0).sort_values(ascending=False)\n",
    "print(top_active_nodes.head(10))\n",
    "top_active_nodes.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f519a849be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFsCAYAAAA30fmmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51a26108d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example distribution of latent layer\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(encoded_rnaseq_df.iloc[:, 4], encoded_rnaseq_df.iloc[:, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoded representation layer also recapitulates signal identified in raw data\n",
    "\n",
    "Perform a t-sne on the data to visualize if the latent layer recapitulates relationships observed through raw data t-sne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcga_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0047-01</th>\n",
       "      <td>13.789300</td>\n",
       "      <td>-7.939112</td>\n",
       "      <td>-2.969391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0055-01</th>\n",
       "      <td>8.301288</td>\n",
       "      <td>-5.550647</td>\n",
       "      <td>-1.020993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-2483-01</th>\n",
       "      <td>16.265942</td>\n",
       "      <td>-8.919164</td>\n",
       "      <td>-1.453329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-2485-01</th>\n",
       "      <td>14.838730</td>\n",
       "      <td>-7.041953</td>\n",
       "      <td>-2.673177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-2486-01</th>\n",
       "      <td>12.671350</td>\n",
       "      <td>-6.479059</td>\n",
       "      <td>-0.813343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         1         2         3\n",
       "tcga_id                                       \n",
       "TCGA-02-0047-01  13.789300 -7.939112 -2.969391\n",
       "TCGA-02-0055-01   8.301288 -5.550647 -1.020993\n",
       "TCGA-02-2483-01  16.265942 -8.919164 -1.453329\n",
       "TCGA-02-2485-01  14.838730 -7.041953 -2.673177\n",
       "TCGA-02-2486-01  12.671350 -6.479059 -0.813343"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components=3, init='pca', random_state=0, perplexity=20,\n",
    "                     learning_rate=300, n_iter=400)\n",
    "tsne_out = tsne.fit_transform(encoded_rnaseq_df)\n",
    "tsne_out = pd.DataFrame(tsne_out, columns=['1', '2', '3'])\n",
    "tsne_out.index = encoded_rnaseq_df.index\n",
    "tsne_out.index.name = 'tcga_id'\n",
    "tsne_out_file = os.path.join('models', 'onehidden_warmup_batchnorm_tsne_out.tsv')\n",
    "tsne_out.to_csv(tsne_out_file, sep='\\t')\n",
    "tsne_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder (generative) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build a generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim, ))  # can generate from any sampled z vector\n",
    "_x_decoded_mean = decoder_to_reconstruct(decoder_input)\n",
    "decoder = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPS4Y1</th>\n",
       "      <th>XIST</th>\n",
       "      <th>KRT5</th>\n",
       "      <th>AGR2</th>\n",
       "      <th>CEACAM5</th>\n",
       "      <th>KRT6A</th>\n",
       "      <th>KRT14</th>\n",
       "      <th>CEACAM6</th>\n",
       "      <th>DDX3Y</th>\n",
       "      <th>KDM5D</th>\n",
       "      <th>...</th>\n",
       "      <th>FAM129A</th>\n",
       "      <th>C8orf48</th>\n",
       "      <th>CDK5R1</th>\n",
       "      <th>FAM81A</th>\n",
       "      <th>C13orf18</th>\n",
       "      <th>GDPD3</th>\n",
       "      <th>SMAGP</th>\n",
       "      <th>C2orf85</th>\n",
       "      <th>POU5F1B</th>\n",
       "      <th>CHST2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcga_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0047-01</th>\n",
       "      <td>0.607967</td>\n",
       "      <td>0.268228</td>\n",
       "      <td>0.205705</td>\n",
       "      <td>0.047186</td>\n",
       "      <td>0.032732</td>\n",
       "      <td>0.062098</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>0.050735</td>\n",
       "      <td>0.639139</td>\n",
       "      <td>0.611527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453891</td>\n",
       "      <td>0.536780</td>\n",
       "      <td>0.749142</td>\n",
       "      <td>0.676382</td>\n",
       "      <td>0.599239</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>0.418983</td>\n",
       "      <td>0.562896</td>\n",
       "      <td>0.234436</td>\n",
       "      <td>0.640018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0055-01</th>\n",
       "      <td>0.123437</td>\n",
       "      <td>0.600167</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.055252</td>\n",
       "      <td>0.156149</td>\n",
       "      <td>0.142619</td>\n",
       "      <td>0.086389</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.073298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563861</td>\n",
       "      <td>0.558564</td>\n",
       "      <td>0.614214</td>\n",
       "      <td>0.575927</td>\n",
       "      <td>0.607690</td>\n",
       "      <td>0.362068</td>\n",
       "      <td>0.543827</td>\n",
       "      <td>0.240139</td>\n",
       "      <td>0.206170</td>\n",
       "      <td>0.652346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-2483-01</th>\n",
       "      <td>0.640520</td>\n",
       "      <td>0.197252</td>\n",
       "      <td>0.138103</td>\n",
       "      <td>0.047335</td>\n",
       "      <td>0.037689</td>\n",
       "      <td>0.044190</td>\n",
       "      <td>0.048368</td>\n",
       "      <td>0.051563</td>\n",
       "      <td>0.608774</td>\n",
       "      <td>0.557177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399787</td>\n",
       "      <td>0.502866</td>\n",
       "      <td>0.733129</td>\n",
       "      <td>0.575510</td>\n",
       "      <td>0.488330</td>\n",
       "      <td>0.363139</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>0.492279</td>\n",
       "      <td>0.208298</td>\n",
       "      <td>0.601181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RPS4Y1      XIST      KRT5      AGR2   CEACAM5     KRT6A  \\\n",
       "tcga_id                                                                       \n",
       "TCGA-02-0047-01  0.607967  0.268228  0.205705  0.047186  0.032732  0.062098   \n",
       "TCGA-02-0055-01  0.123437  0.600167  0.255900  0.118038  0.055252  0.156149   \n",
       "TCGA-02-2483-01  0.640520  0.197252  0.138103  0.047335  0.037689  0.044190   \n",
       "\n",
       "                    KRT14   CEACAM6     DDX3Y     KDM5D    ...      FAM129A  \\\n",
       "tcga_id                                                    ...                \n",
       "TCGA-02-0047-01  0.053772  0.050735  0.639139  0.611527    ...     0.453891   \n",
       "TCGA-02-0055-01  0.142619  0.086389  0.098334  0.073298    ...     0.563861   \n",
       "TCGA-02-2483-01  0.048368  0.051563  0.608774  0.557177    ...     0.399787   \n",
       "\n",
       "                  C8orf48    CDK5R1    FAM81A  C13orf18     GDPD3     SMAGP  \\\n",
       "tcga_id                                                                       \n",
       "TCGA-02-0047-01  0.536780  0.749142  0.676382  0.599239  0.394186  0.418983   \n",
       "TCGA-02-0055-01  0.558564  0.614214  0.575927  0.607690  0.362068  0.543827   \n",
       "TCGA-02-2483-01  0.502866  0.733129  0.575510  0.488330  0.363139  0.411724   \n",
       "\n",
       "                  C2orf85   POU5F1B     CHST2  \n",
       "tcga_id                                        \n",
       "TCGA-02-0047-01  0.562896  0.234436  0.640018  \n",
       "TCGA-02-0055-01  0.240139  0.206170  0.652346  \n",
       "TCGA-02-2483-01  0.492279  0.208298  0.601181  \n",
       "\n",
       "[3 rows x 5000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well does the model reconstruct the input RNAseq data\n",
    "input_rnaseq_reconstruct = decoder.predict(np.array(encoded_rnaseq_df))\n",
    "input_rnaseq_reconstruct = pd.DataFrame(input_rnaseq_reconstruct, index=rnaseq_df.index,\n",
    "                                        columns=rnaseq_df.columns)\n",
    "input_rnaseq_reconstruct.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPS4Y1</th>\n",
       "      <th>XIST</th>\n",
       "      <th>KRT5</th>\n",
       "      <th>AGR2</th>\n",
       "      <th>CEACAM5</th>\n",
       "      <th>KRT6A</th>\n",
       "      <th>KRT14</th>\n",
       "      <th>CEACAM6</th>\n",
       "      <th>DDX3Y</th>\n",
       "      <th>KDM5D</th>\n",
       "      <th>...</th>\n",
       "      <th>FAM129A</th>\n",
       "      <th>C8orf48</th>\n",
       "      <th>CDK5R1</th>\n",
       "      <th>FAM81A</th>\n",
       "      <th>C13orf18</th>\n",
       "      <th>GDPD3</th>\n",
       "      <th>SMAGP</th>\n",
       "      <th>C2orf85</th>\n",
       "      <th>POU5F1B</th>\n",
       "      <th>CHST2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcga_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0047-01</th>\n",
       "      <td>0.678296</td>\n",
       "      <td>0.289910</td>\n",
       "      <td>0.034230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.746797</td>\n",
       "      <td>0.687833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440610</td>\n",
       "      <td>0.428782</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.634340</td>\n",
       "      <td>0.580662</td>\n",
       "      <td>0.294313</td>\n",
       "      <td>0.458134</td>\n",
       "      <td>0.478219</td>\n",
       "      <td>0.168263</td>\n",
       "      <td>0.638497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-0055-01</th>\n",
       "      <td>0.200633</td>\n",
       "      <td>0.654917</td>\n",
       "      <td>0.181993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100606</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.092586</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.140642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620658</td>\n",
       "      <td>0.363207</td>\n",
       "      <td>0.592269</td>\n",
       "      <td>0.602755</td>\n",
       "      <td>0.610192</td>\n",
       "      <td>0.374569</td>\n",
       "      <td>0.722420</td>\n",
       "      <td>0.271356</td>\n",
       "      <td>0.160465</td>\n",
       "      <td>0.602560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-02-2483-01</th>\n",
       "      <td>0.785980</td>\n",
       "      <td>0.140842</td>\n",
       "      <td>0.081082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730648</td>\n",
       "      <td>0.657189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437658</td>\n",
       "      <td>0.471489</td>\n",
       "      <td>0.868774</td>\n",
       "      <td>0.471141</td>\n",
       "      <td>0.487212</td>\n",
       "      <td>0.385521</td>\n",
       "      <td>0.466642</td>\n",
       "      <td>0.784059</td>\n",
       "      <td>0.160797</td>\n",
       "      <td>0.557074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RPS4Y1      XIST      KRT5  AGR2  CEACAM5     KRT6A  \\\n",
       "tcga_id                                                                  \n",
       "TCGA-02-0047-01  0.678296  0.289910  0.034230   0.0      0.0  0.084731   \n",
       "TCGA-02-0055-01  0.200633  0.654917  0.181993   0.0      0.0  0.100606   \n",
       "TCGA-02-2483-01  0.785980  0.140842  0.081082   0.0      0.0  0.000000   \n",
       "\n",
       "                    KRT14   CEACAM6     DDX3Y     KDM5D    ...      FAM129A  \\\n",
       "tcga_id                                                    ...                \n",
       "TCGA-02-0047-01  0.031863  0.037709  0.746797  0.687833    ...     0.440610   \n",
       "TCGA-02-0055-01  0.050011  0.092586  0.103725  0.140642    ...     0.620658   \n",
       "TCGA-02-2483-01  0.000000  0.000000  0.730648  0.657189    ...     0.437658   \n",
       "\n",
       "                  C8orf48    CDK5R1    FAM81A  C13orf18     GDPD3     SMAGP  \\\n",
       "tcga_id                                                                       \n",
       "TCGA-02-0047-01  0.428782  0.732819  0.634340  0.580662  0.294313  0.458134   \n",
       "TCGA-02-0055-01  0.363207  0.592269  0.602755  0.610192  0.374569  0.722420   \n",
       "TCGA-02-2483-01  0.471489  0.868774  0.471141  0.487212  0.385521  0.466642   \n",
       "\n",
       "                  C2orf85   POU5F1B     CHST2  \n",
       "tcga_id                                        \n",
       "TCGA-02-0047-01  0.478219  0.168263  0.638497  \n",
       "TCGA-02-0055-01  0.271356  0.160465  0.602560  \n",
       "TCGA-02-2483-01  0.784059  0.160797  0.557074  \n",
       "\n",
       "[3 rows x 5000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnaseq_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the encoder/decoder models for future investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder_model_file = os.path.join('models', 'encoder_onehidden_warmstart_batchnorm_vae.hdf5')\n",
    "decoder_model_file = os.path.join('models', 'decoder_onehidden_warmstart_batchnorm_vae.hdf5')\n",
    "\n",
    "encoder.save(encoder_model_file)\n",
    "decoder.save(decoder_model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
